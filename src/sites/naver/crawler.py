import time
import random
import json
import os
import shutil
import glob
from datetime import datetime
from playwright.sync_api import sync_playwright, TimeoutError as PlaywrightTimeout
from src.core.base_crawler import BaseCrawler
from src.core.config import INPUT_FILE, NAVER_CONFIG
import pandas as pd

# ìŠ¤í…”ìŠ¤ ìŠ¤í¬ë¦½íŠ¸ - ë´‡ ê°ì§€ ìš°íšŒ
STEALTH_JS = """
// 1. webdriver ì†ì„± ìˆ¨ê¸°ê¸°
Object.defineProperty(navigator, 'webdriver', { get: () => undefined });

// 2. Chrome ëŸ°íƒ€ì„ ìœ„ì¥
window.navigator.chrome = { 
    runtime: {},
    loadTimes: function() {},
    csi: function() {},
    app: {}
};

// 3. í”ŒëŸ¬ê·¸ì¸ ìœ„ì¥ (ë¹ˆ ë°°ì—´ì´ë©´ ë´‡ìœ¼ë¡œ ê°ì§€ë¨)
Object.defineProperty(navigator, 'plugins', {
    get: () => [
        { name: 'Chrome PDF Plugin', filename: 'internal-pdf-viewer' },
        { name: 'Chrome PDF Viewer', filename: 'mhjfbmdgcfjbbpaeojofohoefgiehjai' },
        { name: 'Native Client', filename: 'internal-nacl-plugin' }
    ]
});

// 4. ì–¸ì–´ ì„¤ì •
Object.defineProperty(navigator, 'languages', {
    get: () => ['ko-KR', 'ko', 'en-US', 'en']
});

// 5. ê¶Œí•œ API ìœ„ì¥
const originalQuery = window.navigator.permissions.query;
window.navigator.permissions.query = (parameters) => (
    parameters.name === 'notifications' ?
        Promise.resolve({ state: Notification.permission }) :
        originalQuery(parameters)
);

// 6. ìë™í™” ê´€ë ¨ ì†ì„± ì œê±°
delete window.cdc_adoQpoasnfa76pfcZLmcfl_Array;
delete window.cdc_adoQpoasnfa76pfcZLmcfl_Promise;
delete window.cdc_adoQpoasnfa76pfcZLmcfl_Symbol;

// 7. WebGL ë Œë”ëŸ¬ ì •ë³´ ìœ„ì¥ (ì„ íƒì )
const getParameterProxyHandler = {
    apply: function(target, thisArg, argumentsList) {
        const param = argumentsList[0];
        const gl = thisArg;
        if (param === 37445) {
            return 'Google Inc. (Apple)';
        }
        if (param === 37446) {
            return 'ANGLE (Apple, Apple M1 Pro, OpenGL 4.1)';
        }
        return Reflect.apply(target, thisArg, argumentsList);
    }
};

try {
    const canvas = document.createElement('canvas');
    const gl = canvas.getContext('webgl') || canvas.getContext('experimental-webgl');
    if (gl) {
        gl.getParameter = new Proxy(gl.getParameter.bind(gl), getParameterProxyHandler);
    }
} catch(e) {}
"""


class CrawlStats:
    """í¬ë¡¤ë§ í†µê³„ ë° ì§„í–‰ ìƒí™© ì¶”ì """

    def __init__(self):
        self.reset()

    def reset(self):
        self.start_time = None
        self.total_pages = 0
        self.total_reviews = 0
        self.current_page = 0
        self.errors = []
        self.warnings = []
        self.pages_per_second = 0
        self.reviews_per_second = 0
        self.skipped_reviews = 0  # ì´ë¯¸ ìˆ˜ì§‘ëœ ë¦¬ë·° (ìŠ¤í‚µ)

    def start(self, total_pages=0, total_reviews=0):
        self.start_time = time.time()
        self.total_pages = total_pages
        self.total_reviews = total_reviews

    def update(self, current_page, collected_reviews):
        self.current_page = current_page
        elapsed = time.time() - self.start_time if self.start_time else 1
        self.pages_per_second = current_page / elapsed if elapsed > 0 else 0
        self.reviews_per_second = collected_reviews / elapsed if elapsed > 0 else 0

    def add_error(self, error_msg):
        timestamp = datetime.now().strftime("%H:%M:%S")
        self.errors.append(f"[{timestamp}] {error_msg}")

    def add_warning(self, warning_msg):
        timestamp = datetime.now().strftime("%H:%M:%S")
        self.warnings.append(f"[{timestamp}] {warning_msg}")

    def get_progress_str(self, collected_reviews):
        elapsed = time.time() - self.start_time if self.start_time else 0
        elapsed_str = time.strftime("%H:%M:%S", time.gmtime(elapsed))

        if self.total_pages > 0:
            progress_pct = (self.current_page / self.total_pages) * 100
            remaining_pages = self.total_pages - self.current_page
            eta_seconds = (
                remaining_pages / self.pages_per_second
                if self.pages_per_second > 0
                else 0
            )
            eta_str = time.strftime("%H:%M:%S", time.gmtime(eta_seconds))
        else:
            progress_pct = 0
            eta_str = "ê³„ì‚°ì¤‘..."

        skip_str = (
            f" (Skip: {self.skipped_reviews})" if self.skipped_reviews > 0 else ""
        )

        return (
            f"[{progress_pct:5.1f}%] "
            f"Page {self.current_page:,}/{self.total_pages:,} | "
            f"Reviews: {collected_reviews:,}{skip_str} | "
            f"Speed: {self.pages_per_second:.1f}p/s | "
            f"Elapsed: {elapsed_str} | ETA: {eta_str}"
        )

    def get_summary(self, collected_reviews):
        elapsed = time.time() - self.start_time if self.start_time else 0
        elapsed_str = time.strftime("%H:%M:%S", time.gmtime(elapsed))

        summary = [
            "",
            "=" * 60,
            "ğŸ“Š í¬ë¡¤ë§ ì™„ë£Œ ìš”ì•½",
            "=" * 60,
            f"  âœ… ì´ í˜ì´ì§€: {self.current_page:,}í˜ì´ì§€",
            f"  âœ… ì‹ ê·œ ë¦¬ë·°: {collected_reviews:,}ê°œ",
        ]

        if self.skipped_reviews > 0:
            summary.append(f"  â­ï¸  ìŠ¤í‚µ ë¦¬ë·°: {self.skipped_reviews:,}ê°œ (ì´ë¯¸ ìˆ˜ì§‘ë¨)")

        summary.extend(
            [
                f"  â±ï¸  ì†Œìš” ì‹œê°„: {elapsed_str}",
                f"  ğŸš€ í‰ê·  ì†ë„: {self.pages_per_second:.2f}í˜ì´ì§€/ì´ˆ",
            ]
        )

        if self.errors:
            summary.append(f"  âŒ ì˜¤ë¥˜: {len(self.errors)}ê±´")
            for err in self.errors[-5:]:
                summary.append(f"     - {err}")

        if self.warnings:
            summary.append(f"  âš ï¸  ê²½ê³ : {len(self.warnings)}ê±´")

        summary.append("=" * 60)
        return "\n".join(summary)


class NaverCrawler(BaseCrawler):
    def __init__(self):
        super().__init__(site_name="naver")
        self.collected_reviews = []
        self.saved_ids = set()
        self.current_file_path = None
        self.unsaved_reviews = []
        self.save_batch_size = NAVER_CONFIG.get("save_batch_size", 100)
        self.stats = CrawlStats()

        # ì˜¤ë¥˜ ëŒ€ì‘ ì„¤ì • ê°•í™”
        self.max_retries = 5  # ì¬ì‹œë„ íšŸìˆ˜ ì¦ê°€
        self.retry_delay = 10
        self.pagination_retry_max = 3  # í˜ì´ì§€ë„¤ì´ì…˜ ì¬ì‹œë„ íšŸìˆ˜
        self.block_detection_keywords = [
            "ì ‘ê·¼ì´ ì°¨ë‹¨",
            "ë¹„ì •ìƒì ì¸ ì ‘ê·¼",
            "ìë™í™”ëœ ì ‘ê·¼",
            "captcha",
            "blocked",
            "denied",
        ]

    def _load_existing_reviews(self, prod_id):
        """ê¸°ì¡´ì— ìˆ˜ì§‘ëœ ë¦¬ë·° ID ë¡œë“œ (ì´ì–´ì„œ í¬ë¡¤ë§ìš©)"""
        # ê°€ì¥ ìµœê·¼ í´ë”ì—ì„œ í•´ë‹¹ ìƒí’ˆì˜ JSON íŒŒì¼ ì°¾ê¸°
        base_dir = os.path.join("data", "raw", "naver")
        if not os.path.exists(base_dir):
            return set(), []

        # ë‚ ì§œìˆœìœ¼ë¡œ ì •ë ¬ëœ í´ë” ëª©ë¡
        folders = sorted(
            [
                f
                for f in os.listdir(base_dir)
                if os.path.isdir(os.path.join(base_dir, f))
            ],
            reverse=True,
        )

        for folder in folders:
            file_path = os.path.join(base_dir, folder, f"naver_reviews_{prod_id}.json")
            if os.path.exists(file_path):
                try:
                    with open(file_path, "r", encoding="utf-8") as f:
                        existing_reviews = json.load(f)

                    existing_ids = {
                        r.get("id") for r in existing_reviews if r.get("id")
                    }
                    print(f"   ğŸ“‚ ê¸°ì¡´ ë°ì´í„° ë°œê²¬: {file_path}")
                    print(f"   ğŸ“Š ê¸°ì¡´ ë¦¬ë·°: {len(existing_ids):,}ê°œ")
                    return existing_ids, existing_reviews
                except Exception as e:
                    print(f"   âš ï¸  ê¸°ì¡´ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")

        return set(), []

    def handle_response(self, response):
        """API ì‘ë‹µì„ ê°€ë¡œì±„ì„œ ë¦¬ë·° ë°ì´í„°ë¥¼ ìˆ˜ì§‘"""
        try:
            url = response.url

            if "/contents/reviews/query-pages" not in url:
                return

            if response.status != 200:
                self.stats.add_warning(f"API returned status {response.status}")
                return

            try:
                data = response.json()
            except:
                return

            total_elements = data.get("totalElements", 0)
            total_pages = data.get("totalPages", 0)
            current_page = data.get("page", 0)

            if current_page == 1 and total_elements > 0:
                self.stats.start(total_pages, total_elements)
                print(
                    f"\n   ğŸ“‹ ì „ì²´ ë¦¬ë·°: {total_elements:,}ê°œ ({total_pages:,}í˜ì´ì§€)"
                )

            contents = data.get("contents", [])
            if not contents:
                return

            new_reviews = []
            skipped = 0
            for review in contents:
                review_id = review.get("id")

                if not review_id:
                    continue

                if review_id in self.saved_ids:
                    skipped += 1
                    continue

                labels = review.get("labels", [])
                if "BEST" in labels:
                    continue

                new_reviews.append(review)
                self.saved_ids.add(review_id)

            self.stats.skipped_reviews += skipped

            if new_reviews:
                self.collected_reviews.extend(new_reviews)
                self.unsaved_reviews.extend(new_reviews)

                self.stats.update(current_page, len(self.collected_reviews))

                if len(self.unsaved_reviews) >= self.save_batch_size:
                    self._save_reviews_batch()

                print(
                    f"\r   {self.stats.get_progress_str(len(self.collected_reviews))}",
                    end="",
                    flush=True,
                )

        except Exception as e:
            self.stats.add_error(f"handle_response: {type(e).__name__}: {str(e)[:50]}")

    def _check_blocked(self, page):
        """ì°¨ë‹¨ ì—¬ë¶€ í™•ì¸"""
        try:
            page_content = page.content().lower()
            page_title = page.title().lower()

            for keyword in self.block_detection_keywords:
                if keyword in page_content or keyword in page_title:
                    return True, keyword

            if "ì—ëŸ¬" in page_title or "error" in page_title:
                return True, "error page"

            return False, None
        except:
            return False, None

    def _handle_block(self, page, reason):
        """ì°¨ë‹¨ ê°ì§€ ì‹œ ëŒ€ì‘"""
        self.stats.add_error(f"ğŸš« ì°¨ë‹¨ ê°ì§€: {reason}")
        print(f"\n\n   âš ï¸  ì°¨ë‹¨ ê°ì§€ë¨: {reason}")
        print(f"   â³ {self.retry_delay}ì´ˆ í›„ ì¬ì‹œë„...")

        if self.unsaved_reviews:
            self._save_reviews_batch()
            print(f"   ğŸ’¾ í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ë°ì´í„° ì €ì¥ ì™„ë£Œ")

        time.sleep(self.retry_delay)

        try:
            page.reload(wait_until="domcontentloaded")
            time.sleep(3)

            is_blocked, _ = self._check_blocked(page)
            if is_blocked:
                print(f"   âŒ ì—¬ì „íˆ ì°¨ë‹¨ë¨. ë” ê¸´ ëŒ€ê¸° ì‹œê°„ ì ìš©...")
                time.sleep(self.retry_delay * 3)
                return False
            return True
        except:
            return False

    def _click_next_group(self, page):
        """'ë‹¤ìŒ' ë²„íŠ¼ í´ë¦­í•˜ì—¬ 10í˜ì´ì§€ ê·¸ë£¹ ê±´ë„ˆë›°ê¸°

        Returns:
            (success, new_page_num): ì„±ê³µ ì—¬ë¶€ì™€ ìƒˆ í˜ì´ì§€ ë²ˆí˜¸
        """
        page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
        time.sleep(0.3)

        # "ë‹¤ìŒ" ë²„íŠ¼ ì°¾ê¸°
        next_btn_selectors = [
            "a[data-shp-area='revlist.pgn']:has-text('ë‹¤ìŒ'):not([aria-hidden='true'])",
            "a:has-text('ë‹¤ìŒ'):visible",
        ]

        for selector in next_btn_selectors:
            try:
                next_btn = page.locator(selector).first
                if next_btn.count() > 0 and next_btn.is_visible():
                    aria_hidden = next_btn.get_attribute("aria-hidden")
                    if aria_hidden == "true":
                        continue

                    # í´ë¦­ ì „ í˜„ì¬ í˜ì´ì§€ ê·¸ë£¹ í™•ì¸
                    try:
                        with page.expect_response(
                            lambda r: "reviews" in r.url, timeout=5000
                        ):
                            next_btn.click(force=True)
                        time.sleep(0.3)
                        return True
                    except:
                        pass
            except:
                continue

        return False

    def _skip_to_page(self, page, target_page):
        """'ë‹¤ìŒ' ë²„íŠ¼ì„ ë°˜ë³µ í´ë¦­í•˜ì—¬ ëª©í‘œ í˜ì´ì§€ ê·¼ì²˜ê¹Œì§€ ë¹ ë¥´ê²Œ ìŠ¤í‚µ

        Args:
            page: Playwright í˜ì´ì§€ ê°ì²´
            target_page: ëª©í‘œ í˜ì´ì§€ ë²ˆí˜¸

        Returns:
            ì‹¤ì œ ë„ë‹¬í•œ í˜ì´ì§€ ë²ˆí˜¸
        """
        # 10í˜ì´ì§€ ê·¸ë£¹ ìˆ˜ ê³„ì‚° (ì˜ˆ: 157í˜ì´ì§€ -> 15ë²ˆ "ë‹¤ìŒ" í´ë¦­)
        groups_to_skip = (target_page - 1) // 10

        if groups_to_skip <= 0:
            return 1

        print(f"\n   â© ë¹ ë¥¸ ìŠ¤í‚µ: 'ë‹¤ìŒ' ë²„íŠ¼ {groups_to_skip}ë²ˆ í´ë¦­ ì˜ˆì •")

        current_group = 0
        for i in range(groups_to_skip):
            success = self._click_next_group(page)

            if success:
                current_group += 1
                # ì§„í–‰ ìƒí™© í‘œì‹œ
                if (i + 1) % 5 == 0 or i == groups_to_skip - 1:
                    estimated_page = (current_group * 10) + 1
                    print(
                        f"   â© ìŠ¤í‚µ ì§„í–‰: {current_group}/{groups_to_skip} ({estimated_page}í˜ì´ì§€ ê·¼ì²˜)"
                    )
            else:
                print(
                    f"\n   âš ï¸ ìŠ¤í‚µ ì¤‘ë‹¨: {current_group}ë²ˆì§¸ ê·¸ë£¹ì—ì„œ 'ë‹¤ìŒ' ë²„íŠ¼ ì—†ìŒ"
                )
                break

            # 10ë²ˆë§ˆë‹¤ ì ì‹œ ì¿¨ë‹¤ìš´ (ì°¨ë‹¨ ë°©ì§€)
            if (i + 1) % 10 == 0:
                time.sleep(random.uniform(1.0, 2.0))

        # ë„ë‹¬í•œ í˜ì´ì§€ ë²ˆí˜¸ ê³„ì‚° (ê·¸ë£¹ * 10 + 1)
        reached_page = (current_group * 10) + 1
        print(f"   âœ… ìŠ¤í‚µ ì™„ë£Œ: ì•½ {reached_page}í˜ì´ì§€ ë„ë‹¬")

        return reached_page

    def _cooldown(self, seconds, reason="ì°¨ë‹¨ ê°ì§€"):
        """ì¿¨ë‹¤ìš´ ëŒ€ê¸°

        Args:
            seconds: ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
            reason: ì¿¨ë‹¤ìš´ ì´ìœ 
        """
        print(f"\n   â„ï¸  ì¿¨ë‹¤ìš´: {reason}")
        for remaining in range(seconds, 0, -10):
            print(f"   â³ {remaining}ì´ˆ ë‚¨ìŒ...", end="\r", flush=True)
            time.sleep(min(10, remaining))
        print(f"   âœ… ì¿¨ë‹¤ìš´ ì™„ë£Œ, ì¬ì‹œë„í•©ë‹ˆë‹¤...")

    def _click_next_page(self, page, current_page):
        """ë‹¤ìŒ í˜ì´ì§€ í´ë¦­ - ê°•í™”ëœ ì¬ì‹œë„ ë¡œì§

        Args:
            page: Playwright í˜ì´ì§€ ê°ì²´
            current_page: í˜„ì¬ í˜ì´ì§€ ë²ˆí˜¸
        """
        next_page_num = current_page + 1
        delay_min = NAVER_CONFIG.get("page_delay_min", 0.8)
        delay_max = NAVER_CONFIG.get("page_delay_max", 1.5)

        for attempt in range(self.pagination_retry_max):
            # ìŠ¤í¬ë¡¤ì„ ë‚´ë ¤ì„œ í˜ì´ì§€ë„¤ì´ì…˜ ì˜ì—­ í™•ì‹¤íˆ ë¡œë”©
            page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            time.sleep(0.5)

            # ë°©ë²• 1: ì •í™•í•œ í˜ì´ì§€ ë²ˆí˜¸ ë²„íŠ¼
            next_num_selector = f"a[data-shp-area='revlist.pgn'][data-shp-contents-id='{next_page_num}']"
            next_num_btn = page.locator(next_num_selector).first

            if next_num_btn.count() > 0 and next_num_btn.is_visible():
                try:
                    with page.expect_response(
                        lambda r: "reviews" in r.url, timeout=10000
                    ):
                        next_num_btn.click(force=True)
                    time.sleep(random.uniform(delay_min, delay_max))
                    return True, None
                except Exception as e:
                    self.stats.add_warning(
                        f"Page {current_page}: ë²„íŠ¼ í´ë¦­ ì‹¤íŒ¨ ({attempt+1})"
                    )

            # ë°©ë²• 2: "ë‹¤ìŒ" ë²„íŠ¼ ì°¾ê¸° (10í˜ì´ì§€ ê·¸ë£¹ ë„˜ì–´ê°ˆ ë•Œ)
            next_btn_selectors = [
                "a[data-shp-area='revlist.pgn']:has-text('ë‹¤ìŒ'):not([aria-hidden='true'])",
                "a:has-text('ë‹¤ìŒ'):visible",
            ]

            for selector in next_btn_selectors:
                try:
                    next_btn = page.locator(selector).first
                    if next_btn.count() > 0 and next_btn.is_visible():
                        aria_hidden = next_btn.get_attribute("aria-hidden")
                        if aria_hidden == "true":
                            continue

                        try:
                            with page.expect_response(
                                lambda r: "reviews" in r.url, timeout=10000
                            ):
                                next_btn.click(force=True)
                            time.sleep(random.uniform(delay_min, delay_max))
                            return True, None
                        except:
                            pass
                except:
                    continue

            # ë°©ë²• 3: ëª¨ë“  í˜ì´ì§€ë„¤ì´ì…˜ ë²„íŠ¼ ìˆœíšŒ
            try:
                all_pgn_btns = page.locator("a[data-shp-area='revlist.pgn']").all()
                for btn in all_pgn_btns:
                    try:
                        text = btn.text_content().strip()
                        aria_hidden = btn.get_attribute("aria-hidden")
                        contents_id = btn.get_attribute("data-shp-contents-id")

                        if (
                            text == "ë‹¤ìŒ" and aria_hidden != "true"
                        ) or contents_id == str(next_page_num):
                            try:
                                with page.expect_response(
                                    lambda r: "reviews" in r.url, timeout=10000
                                ):
                                    btn.click(force=True)
                                time.sleep(random.uniform(delay_min, delay_max))
                                return True, None
                            except:
                                pass
                    except:
                        continue
            except:
                pass

            # ì¬ì‹œë„ ì „ ëŒ€ê¸°
            if attempt < self.pagination_retry_max - 1:
                print(
                    f"\n   ğŸ”„ í˜ì´ì§€ë„¤ì´ì…˜ ì¬ì‹œë„ ({attempt + 2}/{self.pagination_retry_max})..."
                )
                time.sleep(2)
                page.evaluate("window.scrollTo(0, document.body.scrollHeight - 500)")
                time.sleep(1)

        return False, "ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ"

    def get_targets(self):
        print(f"ğŸ“‚ íƒ€ê²Ÿ íŒŒì¼ ë¡œë”©: {INPUT_FILE}")
        try:
            df = pd.read_excel(INPUT_FILE)
            p_col = [c for c in df.columns if "í”Œë«í¼" in str(c)][0]
            naver_df = df[
                df[p_col]
                .astype(str)
                .str.contains("ë„¤ì´ë²„|ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´", case=False, na=False)
            ]
            print(f"   âœ… ë„¤ì´ë²„ ìƒí’ˆ {len(naver_df)}ê°œ ë°œê²¬")
            return naver_df
        except Exception as e:
            self.stats.add_error(f"íƒ€ê²Ÿ íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {e}")
            print(f"   âŒ ì˜¤ë¥˜: {e}")
            return pd.DataFrame()

    def crawl_product(self, page, url, product_index=0, total_products=0):
        """ë‹¨ì¼ ìƒí’ˆ í¬ë¡¤ë§ - ì´ì–´ì„œ í¬ë¡¤ë§ ì§€ì›"""
        print(f"\n{'='*60}")
        print(f"ğŸ›’ ìƒí’ˆ [{product_index}/{total_products}]: {url}")
        print(f"{'='*60}")

        self.collected_reviews = []
        self.unsaved_reviews = []
        self.stats.reset()

        # ìƒí’ˆ ID ì¶”ì¶œ
        try:
            prod_id = (
                url.split("/products/")[-1].split("?")[0].split("#")[0]
                if "/products/" in url
                else "unknown"
            )
        except:
            prod_id = "unknown"

        # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ (ì´ì–´ì„œ í¬ë¡¤ë§)
        existing_ids, existing_reviews = self._load_existing_reviews(prod_id)
        self.saved_ids = existing_ids.copy()

        # ìŠ¤í‚µí•  í˜ì´ì§€ ìˆ˜ ê³„ì‚° (ê¸°ì¡´ ë¦¬ë·° ìˆ˜ / í˜ì´ì§€ë‹¹ 20ê°œ)
        self.skip_to_page = len(existing_ids) // 20 if existing_ids else 0

        # íŒŒì¼ ê²½ë¡œ ì„¤ì •
        filename = f"naver_reviews_{prod_id}.json"
        self._ensure_directory()
        self.current_file_path = os.path.join(self.current_output_dir, filename)

        # ê¸°ì¡´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ í˜„ì¬ íŒŒì¼ì— ë³µì‚¬
        if existing_reviews:
            with open(self.current_file_path, "w", encoding="utf-8") as f:
                json.dump(existing_reviews, f, ensure_ascii=False, indent=2)
            print(f"   ğŸ“‹ ê¸°ì¡´ {len(existing_reviews):,}ê°œ ë¦¬ë·° ë¡œë“œë¨")
            if self.skip_to_page > 0:
                print(f"   â© ì•½ {self.skip_to_page}í˜ì´ì§€ê¹Œì§€ ë¹ ë¥´ê²Œ ìŠ¤í‚µ ì˜ˆì •")

        print(f"   ğŸ’¾ ì €ì¥ ê²½ë¡œ: {self.current_file_path}")

        retry_count = 0

        while retry_count < self.max_retries:
            try:
                # 1. í˜ì´ì§€ ì´ë™
                target_url = url if "#REVIEW" in url else f"{url}#REVIEW"
                print(f"   ğŸŒ í˜ì´ì§€ ë¡œë”© ì¤‘...")
                page.goto(target_url, wait_until="domcontentloaded", timeout=30000)
                time.sleep(3)

                # ì°¨ë‹¨ í™•ì¸
                is_blocked, reason = self._check_blocked(page)
                if is_blocked:
                    if not self._handle_block(page, reason):
                        retry_count += 1
                        continue

                # 2. ë¦¬ë·° íƒ­ í™œì„±í™”
                print(f"   ğŸ“‘ ë¦¬ë·° íƒ­ í™œì„±í™” ì¤‘...")
                review_tab_selector = "a[data-name='REVIEW']"

                try:
                    review_btn = page.locator(review_tab_selector).first
                    if review_btn.is_visible():
                        is_active = (
                            review_btn.get_attribute("aria-current") == "true"
                            or review_btn.get_attribute("aria-selected") == "true"
                        )
                        if not is_active:
                            review_btn.click()
                            time.sleep(3)
                    else:
                        page.locator("a:has-text('ë¦¬ë·°')").first.click()
                        time.sleep(3)
                except Exception as e:
                    self.stats.add_warning(f"ë¦¬ë·° íƒ­ í´ë¦­ ì‹¤íŒ¨: {e}")

                # 3. ìµœì‹ ìˆœ ì •ë ¬
                print(f"   ğŸ”„ ìµœì‹ ìˆœ ì •ë ¬ ì¤‘...")
                page.mouse.wheel(0, 500)
                time.sleep(1)

                sort_btn = page.locator("a:has-text('ìµœì‹ ìˆœ')").first
                if sort_btn.is_visible():
                    try:
                        with page.expect_response(
                            lambda r: "reviews" in r.url, timeout=5000
                        ):
                            sort_btn.click(force=True)
                    except:
                        self.stats.add_warning("ìµœì‹ ìˆœ ì •ë ¬ ì‘ë‹µ íƒ€ì„ì•„ì›ƒ")
                    time.sleep(2)

                # 4. í˜ì´ì§€ë„¤ì´ì…˜
                print(f"   ğŸ“„ ë¦¬ë·° ìˆ˜ì§‘ ì‹œì‘...")
                max_pages = 99999
                consecutive_failures = 0
                max_consecutive_failures = 5
                cooldown_count = 0
                max_cooldowns = 3  # ìµœëŒ€ ì¿¨ë‹¤ìš´ íšŸìˆ˜

                # ë¹ ë¥¸ ìŠ¤í‚µ: 'ë‹¤ìŒ' ë²„íŠ¼ìœ¼ë¡œ 10í˜ì´ì§€ì”© ê±´ë„ˆë›°ê¸°
                skip_target = getattr(self, "skip_to_page", 0)
                if skip_target > 10:
                    current_page = self._skip_to_page(page, skip_target)
                else:
                    current_page = 1

                while current_page < max_pages:
                    # ë‹¤ìŒ í˜ì´ì§€ í´ë¦­
                    success, error = self._click_next_page(page, current_page)

                    if success:
                        current_page += 1
                        consecutive_failures = 0
                    else:
                        consecutive_failures += 1

                        # ë¦¬ë·°ê°€ ë¡œë”©ë˜ì§€ ì•ŠìŒ = ì°¨ë‹¨ ê°€ëŠ¥ì„±
                        if consecutive_failures >= max_consecutive_failures:
                            # í˜„ì¬ê¹Œì§€ ì €ì¥
                            if self.unsaved_reviews:
                                self._save_reviews_batch()

                            # ë§ˆì§€ë§‰ í˜ì´ì§€ì¸ì§€ ë¨¼ì € í™•ì¸
                            if (
                                self.stats.total_pages > 0
                                and current_page >= self.stats.total_pages
                            ):
                                print(
                                    f"\n   âœ… ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬ ({current_page}/{self.stats.total_pages})"
                                )
                                break

                            # ì¿¨ë‹¤ìš´ ì‹œë„
                            if cooldown_count < max_cooldowns:
                                cooldown_count += 1
                                cooldown_seconds = (
                                    30 * cooldown_count
                                )  # 30ì´ˆ, 60ì´ˆ, 90ì´ˆ
                                self._cooldown(
                                    cooldown_seconds,
                                    f"ì—°ì† {consecutive_failures}íšŒ ì‹¤íŒ¨ (ì¿¨ë‹¤ìš´ {cooldown_count}/{max_cooldowns})",
                                )

                                # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ í›„ ì¬ì‹œë„
                                try:
                                    page.reload(wait_until="domcontentloaded")
                                    time.sleep(3)

                                    # ë¦¬ë·° íƒ­ ë‹¤ì‹œ í™œì„±í™”
                                    review_btn = page.locator(
                                        "a[data-name='REVIEW']"
                                    ).first
                                    if review_btn.is_visible():
                                        review_btn.click()
                                        time.sleep(2)

                                    # ìµœì‹ ìˆœ ì •ë ¬ ë‹¤ì‹œ
                                    sort_btn = page.locator(
                                        "a:has-text('ìµœì‹ ìˆœ')"
                                    ).first
                                    if sort_btn.is_visible():
                                        sort_btn.click(force=True)
                                        time.sleep(2)

                                    # í˜„ì¬ í˜ì´ì§€ë¡œ ë‹¤ì‹œ ì´ë™
                                    if current_page > 10:
                                        print(
                                            f"   ğŸ”„ {current_page}í˜ì´ì§€ë¡œ ë³µê·€ ì¤‘..."
                                        )
                                        reached = self._skip_to_page(page, current_page)
                                        current_page = reached

                                    consecutive_failures = 0
                                    continue
                                except Exception as e:
                                    self.stats.add_error(f"ë³µêµ¬ ì‹¤íŒ¨: {e}")
                            else:
                                self.stats.add_error(
                                    f"ìµœëŒ€ ì¿¨ë‹¤ìš´ íšŸìˆ˜ ì´ˆê³¼ (page {current_page})"
                                )
                                break

                        # ë§ˆì§€ë§‰ í˜ì´ì§€ì¸ì§€ í™•ì¸
                        if (
                            self.stats.total_pages > 0
                            and current_page >= self.stats.total_pages
                        ):
                            print(
                                f"\n   âœ… ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬ ({current_page}/{self.stats.total_pages})"
                            )
                            break

                    # ì£¼ê¸°ì  ì°¨ë‹¨ í™•ì¸ (100í˜ì´ì§€ë§ˆë‹¤)
                    if current_page % 100 == 0:
                        is_blocked, reason = self._check_blocked(page)
                        if is_blocked:
                            if cooldown_count < max_cooldowns:
                                cooldown_count += 1
                                self._cooldown(60, f"ì°¨ë‹¨ ê°ì§€: {reason}")
                                if not self._handle_block(page, reason):
                                    break
                            else:
                                break

                # ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ
                break

            except PlaywrightTimeout as e:
                retry_count += 1
                self.stats.add_error(
                    f"íƒ€ì„ì•„ì›ƒ (ì‹œë„ {retry_count}/{self.max_retries})"
                )
                print(
                    f"\n   â° íƒ€ì„ì•„ì›ƒ ë°œìƒ. ì¬ì‹œë„ {retry_count}/{self.max_retries}..."
                )
                time.sleep(self.retry_delay)

            except Exception as e:
                retry_count += 1
                self.stats.add_error(f"{type(e).__name__}: {str(e)[:50]}")
                print(f"\n   âŒ ì˜¤ë¥˜: {e}")
                print(f"   ğŸ”„ ì¬ì‹œë„ {retry_count}/{self.max_retries}...")
                time.sleep(self.retry_delay)

        # ë‚¨ì€ ë¦¬ë·° ì €ì¥
        if self.unsaved_reviews:
            self._save_reviews_batch()

        # ìµœì¢… ìš”ì•½ ì¶œë ¥
        print(self.stats.get_summary(len(self.collected_reviews)))

    def _save_reviews_batch(self):
        """ë°°ì¹˜ë¡œ ë¦¬ë·°ë¥¼ íŒŒì¼ì— ì €ì¥"""
        if not self.current_file_path or not self.unsaved_reviews:
            return

        try:
            if os.path.exists(self.current_file_path):
                with open(self.current_file_path, "r", encoding="utf-8") as f:
                    existing_reviews = json.load(f)
            else:
                existing_reviews = []

            existing_reviews.extend(self.unsaved_reviews)
            existing_reviews.sort(key=lambda x: x.get("createDate", ""), reverse=True)

            with open(self.current_file_path, "w", encoding="utf-8") as f:
                json.dump(existing_reviews, f, ensure_ascii=False, indent=2)

            saved_count = len(self.unsaved_reviews)
            self.unsaved_reviews = []
            print(f"\n   ğŸ’¾ ë°°ì¹˜ ì €ì¥: {saved_count}ê°œ ë¦¬ë·°")

        except Exception as e:
            self.stats.add_error(f"ì €ì¥ ì‹¤íŒ¨: {e}")

    def run(self):
        """ë©”ì¸ ì‹¤í–‰"""
        print("\n" + "=" * 60)
        print("ğŸš€ ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ë¦¬ë·° í¬ë¡¤ëŸ¬ ì‹œì‘")
        print("=" * 60)

        targets = self.get_targets()
        if targets.empty:
            print("âŒ í¬ë¡¤ë§ ëŒ€ìƒ ì—†ìŒ")
            return

        total_products = len(targets)
        print(f"\nğŸ“Š ì´ {total_products}ê°œ ìƒí’ˆ í¬ë¡¤ë§ ì˜ˆì •")
        print(f"ğŸ’¡ ê¸°ì¡´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì´ì–´ì„œ í¬ë¡¤ë§í•©ë‹ˆë‹¤.")

        user_data_dir = os.path.join(os.getcwd(), "browser_profile")
        if os.path.exists(user_data_dir):
            try:
                shutil.rmtree(user_data_dir)
            except:
                pass

        overall_start = time.time()
        completed_products = 0
        total_reviews_all = 0

        with sync_playwright() as p:
            print("\nğŸŒ Chrome ë¸Œë¼ìš°ì € ì‹¤í–‰ ì¤‘...")
            try:
                browser = p.chromium.launch_persistent_context(
                    user_data_dir=user_data_dir,
                    channel=NAVER_CONFIG.get("channel", "chrome"),
                    headless=NAVER_CONFIG.get("headless", False),
                    viewport=NAVER_CONFIG.get(
                        "viewport", {"width": 1600, "height": 900}
                    ),
                    args=[
                        "--disable-blink-features=AutomationControlled",
                        "--no-sandbox",
                    ],
                )
            except Exception as e:
                print(f"âŒ ë¸Œë¼ìš°ì € ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                return

            page = browser.pages[0]
            page.add_init_script(STEALTH_JS)
            page.on("response", self.handle_response)

            product_delay = NAVER_CONFIG.get("product_delay", 5)

            for index, row in targets.iterrows():
                try:
                    addr_col = [c for c in targets.columns if "ì£¼ì†Œ" in str(c)][0]
                    url = row[addr_col]
                except:
                    continue

                completed_products += 1
                self.crawl_product(page, url, completed_products, total_products)
                total_reviews_all += len(self.collected_reviews)

                if completed_products < total_products:
                    print(f"\nâ³ ë‹¤ìŒ ìƒí’ˆê¹Œì§€ {product_delay}ì´ˆ ëŒ€ê¸°...")
                    time.sleep(product_delay)

            browser.close()

        overall_elapsed = time.time() - overall_start
        elapsed_str = time.strftime("%H:%M:%S", time.gmtime(overall_elapsed))

        print("\n" + "=" * 60)
        print("ğŸ‰ ì „ì²´ í¬ë¡¤ë§ ì™„ë£Œ!")
        print("=" * 60)
        print(f"  ğŸ“¦ ì™„ë£Œ ìƒí’ˆ: {completed_products}/{total_products}")
        print(f"  ğŸ“ ì‹ ê·œ ë¦¬ë·°: {total_reviews_all:,}ê°œ")
        print(f"  â±ï¸  ì´ ì†Œìš” ì‹œê°„: {elapsed_str}")
        print(f"  ğŸ“ ì €ì¥ ìœ„ì¹˜: {self.current_output_dir}")
        print("=" * 60)
